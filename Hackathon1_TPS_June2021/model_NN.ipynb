{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "79fa3967558145cfb6ebf42c037e2ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_306611f2b9a2403e85fbaaed6177eea6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_10fd6f242b2842679f49505b2e65c9b4",
              "IPY_MODEL_0b7b10de0fe74da996beafd3733619c3"
            ]
          }
        },
        "306611f2b9a2403e85fbaaed6177eea6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "10fd6f242b2842679f49505b2e65c9b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_db260ed87b7948bd9030194c39e7b194",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 120,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 120,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cb24a6d9cad740bcb76e492deca4e4c9"
          }
        },
        "0b7b10de0fe74da996beafd3733619c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cf43768d3aee4387ba7d30c5fda2b8e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 120/120 [1:17:28&lt;00:00, 38.73s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_316b81be8e9847d3bbd04c2774594e41"
          }
        },
        "db260ed87b7948bd9030194c39e7b194": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cb24a6d9cad740bcb76e492deca4e4c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf43768d3aee4387ba7d30c5fda2b8e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "316b81be8e9847d3bbd04c2774594e41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-xhtNweXicj",
        "outputId": "561032b9-383a-4fe1-ce0f-cb57f623b9a4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koEsNUQPak7U"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDoZ65oya22t",
        "outputId": "82b4cde3-d219-4a78-a245-6e32f2808962"
      },
      "source": [
        "%cd /content/gdrive/My Drive/Kaggle"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6WupQt3a6eU",
        "outputId": "b810062f-e4f8-4bda-fc02-d2b30f18cbbe"
      },
      "source": [
        "!kaggle competitions download -c tabular-playground-series-jun-2021"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4)\n",
            "Downloading sample_submission.csv.zip to /content/gdrive/My Drive/Kaggle\n",
            "  0% 0.00/264k [00:00<?, ?B/s]\n",
            "100% 264k/264k [00:00<00:00, 36.0MB/s]\n",
            "Downloading train.csv.zip to /content/gdrive/My Drive/Kaggle\n",
            " 77% 5.00M/6.49M [00:00<00:00, 20.6MB/s]\n",
            "100% 6.49M/6.49M [00:00<00:00, 25.7MB/s]\n",
            "Downloading test.csv.zip to /content/gdrive/My Drive/Kaggle\n",
            "  0% 0.00/3.14M [00:00<?, ?B/s]\n",
            "100% 3.14M/3.14M [00:00<00:00, 105MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzENHVCna9B1",
        "outputId": "e498bd4a-1d4b-40f7-9313-8ea7e09a2eda"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\t       sample_submission.csv.zip  test.csv.zip\ttrain.csv.zip\n",
            "sample_submission.csv  test.csv\t\t\t  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYbHxVB9bZ3n",
        "outputId": "f7ee689f-0fc5-4f58-d7cb-6812dabbeaaf"
      },
      "source": [
        "!unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  sample_submission.csv.zip\n",
            "replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZrOlL7ebwd0"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset, WeightedRandomSampler\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYg8NzsSby8I"
      },
      "source": [
        "train = pd.read_csv(\"./train.csv\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "KM1kHzOAcRZb",
        "outputId": "29f8a83c-6c0e-46b1-84d0-6e225e60118b"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "      <th>feature_25</th>\n",
              "      <th>feature_26</th>\n",
              "      <th>feature_27</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "      <th>feature_38</th>\n",
              "      <th>feature_39</th>\n",
              "      <th>feature_40</th>\n",
              "      <th>feature_41</th>\n",
              "      <th>feature_42</th>\n",
              "      <th>feature_43</th>\n",
              "      <th>feature_44</th>\n",
              "      <th>feature_45</th>\n",
              "      <th>feature_46</th>\n",
              "      <th>feature_47</th>\n",
              "      <th>feature_48</th>\n",
              "      <th>feature_49</th>\n",
              "      <th>feature_50</th>\n",
              "      <th>feature_51</th>\n",
              "      <th>feature_52</th>\n",
              "      <th>feature_53</th>\n",
              "      <th>feature_54</th>\n",
              "      <th>feature_55</th>\n",
              "      <th>feature_56</th>\n",
              "      <th>feature_57</th>\n",
              "      <th>feature_58</th>\n",
              "      <th>feature_59</th>\n",
              "      <th>feature_60</th>\n",
              "      <th>feature_61</th>\n",
              "      <th>feature_62</th>\n",
              "      <th>feature_63</th>\n",
              "      <th>feature_64</th>\n",
              "      <th>feature_65</th>\n",
              "      <th>feature_66</th>\n",
              "      <th>feature_67</th>\n",
              "      <th>feature_68</th>\n",
              "      <th>feature_69</th>\n",
              "      <th>feature_70</th>\n",
              "      <th>feature_71</th>\n",
              "      <th>feature_72</th>\n",
              "      <th>feature_73</th>\n",
              "      <th>feature_74</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Class_2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  feature_0  feature_1  ...  feature_73  feature_74   target\n",
              "0   0          0          0  ...           0           0  Class_6\n",
              "1   1          0          0  ...           1           0  Class_6\n",
              "2   2          0          0  ...           0           0  Class_2\n",
              "3   3          0          0  ...           3           0  Class_8\n",
              "4   4          1          0  ...           0           0  Class_2\n",
              "\n",
              "[5 rows x 77 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y5UQ0JhccrS"
      },
      "source": [
        "test = pd.read_csv(\"./test.csv\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "yOfkJ8sLclvp",
        "outputId": "69ac1f7a-e3b2-4bf4-eaaa-5fd345a5f133"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "      <th>feature_25</th>\n",
              "      <th>feature_26</th>\n",
              "      <th>feature_27</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>feature_33</th>\n",
              "      <th>feature_34</th>\n",
              "      <th>feature_35</th>\n",
              "      <th>feature_36</th>\n",
              "      <th>feature_37</th>\n",
              "      <th>feature_38</th>\n",
              "      <th>feature_39</th>\n",
              "      <th>feature_40</th>\n",
              "      <th>feature_41</th>\n",
              "      <th>feature_42</th>\n",
              "      <th>feature_43</th>\n",
              "      <th>feature_44</th>\n",
              "      <th>feature_45</th>\n",
              "      <th>feature_46</th>\n",
              "      <th>feature_47</th>\n",
              "      <th>feature_48</th>\n",
              "      <th>feature_49</th>\n",
              "      <th>feature_50</th>\n",
              "      <th>feature_51</th>\n",
              "      <th>feature_52</th>\n",
              "      <th>feature_53</th>\n",
              "      <th>feature_54</th>\n",
              "      <th>feature_55</th>\n",
              "      <th>feature_56</th>\n",
              "      <th>feature_57</th>\n",
              "      <th>feature_58</th>\n",
              "      <th>feature_59</th>\n",
              "      <th>feature_60</th>\n",
              "      <th>feature_61</th>\n",
              "      <th>feature_62</th>\n",
              "      <th>feature_63</th>\n",
              "      <th>feature_64</th>\n",
              "      <th>feature_65</th>\n",
              "      <th>feature_66</th>\n",
              "      <th>feature_67</th>\n",
              "      <th>feature_68</th>\n",
              "      <th>feature_69</th>\n",
              "      <th>feature_70</th>\n",
              "      <th>feature_71</th>\n",
              "      <th>feature_72</th>\n",
              "      <th>feature_73</th>\n",
              "      <th>feature_74</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>200001</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200002</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200003</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200004</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  feature_0  feature_1  ...  feature_72  feature_73  feature_74\n",
              "0  200000          0          0  ...           0           0           0\n",
              "1  200001          1          2  ...           3           0           0\n",
              "2  200002          0          1  ...           2           0           0\n",
              "3  200003          0          0  ...           4           0           0\n",
              "4  200004          0          0  ...           0           1           0\n",
              "\n",
              "[5 rows x 76 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "-EqHvxtIcnOZ",
        "outputId": "f6212ac4-2521-4c40-a656-31cb96739b76"
      },
      "source": [
        "submission = pd.read_csv(\"sample_submission.csv\")\n",
        "submission"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200000</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>200001</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>200002</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>200003</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>200004</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99995</th>\n",
              "      <td>299995</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99996</th>\n",
              "      <td>299996</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99997</th>\n",
              "      <td>299997</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99998</th>\n",
              "      <td>299998</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99999</th>\n",
              "      <td>299999</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "      <td>0.1111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100000 rows Ã— 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  Class_1  Class_2  Class_3  ...  Class_6  Class_7  Class_8  Class_9\n",
              "0      200000   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "1      200001   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "2      200002   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "3      200003   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "4      200004   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "...       ...      ...      ...      ...  ...      ...      ...      ...      ...\n",
              "99995  299995   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "99996  299996   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "99997  299997   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "99998  299998   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "99999  299999   0.1111   0.1111   0.1111  ...   0.1111   0.1111   0.1111   0.1111\n",
              "\n",
              "[100000 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd4w10yrdDLG"
      },
      "source": [
        "target = train.target"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r79zwZq-dQ12"
      },
      "source": [
        "train.drop(\"target\",axis=1,inplace=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tck4iaJ9d2UH"
      },
      "source": [
        "train.drop(\"id\",axis=1,inplace=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0dk4GtpjjMy"
      },
      "source": [
        "test.drop(\"id\",axis=1,inplace=True)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiwP6faAeoJ-"
      },
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(train,target,test_size=0.03,stratify=target,random_state=69)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg90YM6Ij6PX"
      },
      "source": [
        "scaler = MinMaxScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(test)\n",
        "\n",
        "X_train , y_train = np.array(X_train), np.array(y_train)\n",
        "X_val, y_val = np.array(X_val), np.array(y_val)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMPqQ3bClzO4",
        "outputId": "91588ff5-9aae-4125-e8db-9d159f89aa6c"
      },
      "source": [
        "class_to_val = {\n",
        "    \"Class_1\" : 0,\n",
        "    \"Class_2\" : 1,\n",
        "    \"Class_3\" : 2,\n",
        "    \"Class_4\" : 3,\n",
        "    \"Class_5\" : 4,\n",
        "    \"Class_6\" : 5,\n",
        "    \"Class_7\" : 6,\n",
        "    \"Class_8\" : 7,\n",
        "    \"Class_9\" : 8,\n",
        "}\n",
        "val_to_class = {v:k for k,v in class_to_val.items()}\n",
        "for i in range(len(y_train)):\n",
        "  y_train[i] = class_to_val[y_train[i]]\n",
        "\n",
        "y_train "
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([8, 8, 7, ..., 7, 7, 6], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-GXH1jqnoDy",
        "outputId": "996c1408-307d-4a98-964a-7c0483e34595"
      },
      "source": [
        "for i in range(len(y_val)):\n",
        "  y_val[i] = class_to_val[y_val[i]]\n",
        "y_val"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 5, 5, ..., 7, 7, 1], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sYyGRbYlIbt"
      },
      "source": [
        "## Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwLDuppFoHFx"
      },
      "source": [
        "y_train=y_train.astype('int64')\n",
        "y_val = y_val.astype('int64')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIASboEZlEic"
      },
      "source": [
        "class ClassifierDataset(Dataset):\n",
        "  def __init__(self,X_data,y_data):\n",
        "    self.X_data = X_data\n",
        "    self.y_data = y_data\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    return self.X_data[index], self.y_data[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.X_data)\n",
        "\n",
        "train_dataset = ClassifierDataset(torch.from_numpy(X_train).float(),torch.from_numpy(y_train).long())\n",
        "\n",
        "val_dataset = ClassifierDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7rKr4JVn_y7"
      },
      "source": [
        "target_list = []\n",
        "for _, t in train_dataset:\n",
        "    target_list.append(t)\n",
        "    \n",
        "target_list = torch.tensor(target_list)\n",
        "target_list = target_list[torch.randperm(len(target_list))]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r90MJktqrFbO"
      },
      "source": [
        "def get_class_distribution(obj):\n",
        "    count_dict = {\n",
        "        \"Class_1\" : 0,\n",
        "        \"Class_2\" : 0,\n",
        "        \"Class_3\" : 0,\n",
        "        \"Class_4\" : 0,\n",
        "        \"Class_5\" : 0,\n",
        "        \"Class_6\" : 0,\n",
        "        \"Class_7\" : 0,\n",
        "        \"Class_8\" : 0,\n",
        "        \"Class_9\" : 0,\n",
        "    }\n",
        "    \n",
        "    for i in obj:\n",
        "        if i == 0: \n",
        "            count_dict['Class_1'] += 1\n",
        "        elif i == 1: \n",
        "            count_dict['Class_2'] += 1\n",
        "        elif i == 2: \n",
        "            count_dict['Class_3'] += 1\n",
        "        elif i == 3: \n",
        "            count_dict['Class_4'] += 1\n",
        "        elif i == 4: \n",
        "            count_dict['Class_5'] += 1  \n",
        "        elif i == 5: \n",
        "            count_dict['Class_6'] += 1\n",
        "        elif i == 6:\n",
        "            count_dict['Class_7'] += 1 \n",
        "        elif i == 7:\n",
        "            count_dict['Class_8'] += 1\n",
        "        elif i == 8:\n",
        "            count_dict['Class_9'] += 1\n",
        "        else:\n",
        "            print(\"Check classes.\")\n",
        "            \n",
        "    return count_dict"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6ArzBoTpnuO",
        "outputId": "53cf4448-228c-4c8d-da71-e2d8986389b3"
      },
      "source": [
        "class_count = [i for i in get_class_distribution(y_train).values()]\n",
        "print(class_count)\n",
        "class_weights = 1./torch.tensor(class_count, dtype=torch.float)\n",
        "print(class_weights)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8844, 23698, 14354, 4563, 2972, 50257, 14326, 50210, 24776]\n",
            "tensor([1.1307e-04, 4.2198e-05, 6.9667e-05, 2.1915e-04, 3.3647e-04, 1.9898e-05,\n",
            "        6.9803e-05, 1.9916e-05, 4.0362e-05])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k11b5nKVps5A"
      },
      "source": [
        "class_weights_all = class_weights[target_list]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9bqvuhRt76L"
      },
      "source": [
        "weighted_sampler = WeightedRandomSampler(\n",
        "    weights=class_weights_all,\n",
        "    num_samples=len(class_weights_all),\n",
        "    replacement=True\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a__rOqYTJ-U1",
        "outputId": "99b13732-905b-4f1b-f67c-02d8ad18ebf9"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(194000, 75)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoqqAYpzt-bL"
      },
      "source": [
        "EPOCHS = 120\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.0007\n",
        "NUM_FEATURES = X_train.shape[1]\n",
        "NUM_CLASSES = 9"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am-uG4xauAtr"
      },
      "source": [
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          sampler=weighted_sampler\n",
        ")\n",
        "val_loader = DataLoader(dataset=val_dataset, batch_size=1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOlUqjG0uDZF"
      },
      "source": [
        "class MulticlassClassification(nn.Module):\n",
        "    def __init__(self, num_feature, num_class):\n",
        "        super(MulticlassClassification, self).__init__()\n",
        "        \n",
        "        self.layer_1 = nn.Linear(num_feature, 582)\n",
        "        self.layer_2 = nn.Linear(582, 128)\n",
        "        self.layer_3 = nn.Linear(128, 73)\n",
        "        self.layer_out = nn.Linear(73, num_class) \n",
        "        \n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(p=0.33)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(582)\n",
        "        self.batchnorm2 = nn.BatchNorm1d(128)\n",
        "        self.batchnorm3 = nn.BatchNorm1d(73)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.layer_1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        \n",
        "        x = self.layer_2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm2(x)\n",
        "    \n",
        "        \n",
        "        x = self.layer_3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        \n",
        "        x = self.layer_out(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgQLOXVyuRlq",
        "outputId": "83335a0f-7fe2-4f27-b880-dfccec61a69c"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge6FlNgCuUNC",
        "outputId": "6dafca40-c484-4ade-8ca8-052e2b45ebb2"
      },
      "source": [
        "model = MulticlassClassification(num_feature = NUM_FEATURES, num_class=NUM_CLASSES)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device))\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "print(model)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MulticlassClassification(\n",
            "  (layer_1): Linear(in_features=75, out_features=582, bias=True)\n",
            "  (layer_2): Linear(in_features=582, out_features=128, bias=True)\n",
            "  (layer_3): Linear(in_features=128, out_features=73, bias=True)\n",
            "  (layer_out): Linear(in_features=73, out_features=9, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (dropout): Dropout(p=0.33, inplace=False)\n",
            "  (batchnorm1): BatchNorm1d(582, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (batchnorm3): BatchNorm1d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnJ_rNmXuvII"
      },
      "source": [
        "def multi_acc(y_pred, y_test):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
        "    # print(torch.exp(y_pred_softmax),y_pred_softmax.shape)\n",
        "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
        "    \n",
        "    correct_pred = (y_pred_tags == y_test).float()\n",
        "    acc = correct_pred.sum() / len(correct_pred)\n",
        "    \n",
        "    acc = torch.round(acc * 100)\n",
        "    \n",
        "    return acc\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTlb3MHLw9JM"
      },
      "source": [
        "accuracy_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}\n",
        "loss_stats = {\n",
        "    'train': [],\n",
        "    \"val\": []\n",
        "}"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "79fa3967558145cfb6ebf42c037e2ae5",
            "306611f2b9a2403e85fbaaed6177eea6",
            "10fd6f242b2842679f49505b2e65c9b4",
            "0b7b10de0fe74da996beafd3733619c3",
            "db260ed87b7948bd9030194c39e7b194",
            "cb24a6d9cad740bcb76e492deca4e4c9",
            "cf43768d3aee4387ba7d30c5fda2b8e1",
            "316b81be8e9847d3bbd04c2774594e41"
          ]
        },
        "id": "ukdSNvZTw-1n",
        "outputId": "57b4a282-72ea-4ae8-9d82-2e3f8ecaa266"
      },
      "source": [
        "for e in tqdm(range(1, EPOCHS+1)):\n",
        "    \n",
        "    # TRAINING\n",
        "    train_epoch_loss = 0\n",
        "    train_epoch_acc = 0\n",
        "    model.train()\n",
        "    for X_train_batch, y_train_batch in train_loader:\n",
        "        X_train_batch, y_train_batch = X_train_batch.to(device), y_train_batch.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_train_pred = model(X_train_batch)\n",
        "        # print(y_train_pred)\n",
        "        train_loss = criterion(y_train_pred, y_train_batch)\n",
        "        train_acc = multi_acc(y_train_pred, y_train_batch)\n",
        "        \n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_epoch_loss += train_loss.item()\n",
        "        train_epoch_acc += train_acc.item()\n",
        "        \n",
        "        \n",
        "    # VALIDATION    \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        val_epoch_loss = 0\n",
        "        val_epoch_acc = 0\n",
        "        \n",
        "        model.eval()\n",
        "        for X_val_batch, y_val_batch in val_loader:\n",
        "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
        "            \n",
        "            y_val_pred = model(X_val_batch)\n",
        "                        \n",
        "            val_loss = criterion(y_val_pred, y_val_batch)\n",
        "            val_acc = multi_acc(y_val_pred, y_val_batch)\n",
        "            \n",
        "            val_epoch_loss += val_loss.item()\n",
        "            val_epoch_acc += val_acc.item()\n",
        "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
        "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
        "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
        "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
        "                              \n",
        "    \n",
        "    print(f'Epoch {e+0:03}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "79fa3967558145cfb6ebf42c037e2ae5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=120.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 001: | Train Loss: 2.13627 | Val Loss: 1.99798 | Train Acc: 26.458| Val Acc: 32.433\n",
            "Epoch 002: | Train Loss: 2.11325 | Val Loss: 1.99623 | Train Acc: 28.757| Val Acc: 32.033\n",
            "Epoch 003: | Train Loss: 2.10917 | Val Loss: 2.00969 | Train Acc: 29.245| Val Acc: 30.583\n",
            "Epoch 004: | Train Loss: 2.10402 | Val Loss: 2.01322 | Train Acc: 29.609| Val Acc: 31.617\n",
            "Epoch 005: | Train Loss: 2.10183 | Val Loss: 2.00358 | Train Acc: 30.316| Val Acc: 29.150\n",
            "Epoch 006: | Train Loss: 2.09923 | Val Loss: 2.07446 | Train Acc: 29.745| Val Acc: 30.950\n",
            "Epoch 007: | Train Loss: 2.09705 | Val Loss: 2.36036 | Train Acc: 29.874| Val Acc: 30.300\n",
            "Epoch 008: | Train Loss: 2.09976 | Val Loss: 2.66460 | Train Acc: 29.634| Val Acc: 30.717\n",
            "Epoch 009: | Train Loss: 2.09747 | Val Loss: 41.76695 | Train Acc: 29.809| Val Acc: 30.433\n",
            "Epoch 010: | Train Loss: 2.09388 | Val Loss: 90.07449 | Train Acc: 29.671| Val Acc: 26.167\n",
            "Epoch 011: | Train Loss: 2.09655 | Val Loss: 30.52703 | Train Acc: 29.855| Val Acc: 27.367\n",
            "Epoch 012: | Train Loss: 2.09355 | Val Loss: 25.76910 | Train Acc: 29.420| Val Acc: 25.933\n",
            "Epoch 013: | Train Loss: 2.09279 | Val Loss: 66.23054 | Train Acc: 29.025| Val Acc: 29.717\n",
            "Epoch 014: | Train Loss: 2.09280 | Val Loss: 643.46048 | Train Acc: 29.051| Val Acc: 30.233\n",
            "Epoch 015: | Train Loss: 2.09468 | Val Loss: 4.22268 | Train Acc: 29.505| Val Acc: 29.383\n",
            "Epoch 016: | Train Loss: 2.09144 | Val Loss: 16.70723 | Train Acc: 29.362| Val Acc: 28.517\n",
            "Epoch 017: | Train Loss: 2.08520 | Val Loss: 10.38327 | Train Acc: 29.606| Val Acc: 28.733\n",
            "Epoch 018: | Train Loss: 2.08978 | Val Loss: 226.76033 | Train Acc: 29.301| Val Acc: 29.333\n",
            "Epoch 019: | Train Loss: 2.08892 | Val Loss: 1111.23557 | Train Acc: 29.489| Val Acc: 29.250\n",
            "Epoch 020: | Train Loss: 2.08706 | Val Loss: 1024.06206 | Train Acc: 29.421| Val Acc: 28.317\n",
            "Epoch 021: | Train Loss: 2.08640 | Val Loss: 596.43579 | Train Acc: 29.712| Val Acc: 29.150\n",
            "Epoch 022: | Train Loss: 2.08751 | Val Loss: 10785.97185 | Train Acc: 28.994| Val Acc: 30.533\n",
            "Epoch 023: | Train Loss: 2.08899 | Val Loss: 8122.72365 | Train Acc: 28.913| Val Acc: 29.300\n",
            "Epoch 024: | Train Loss: 2.08476 | Val Loss: 8282.86446 | Train Acc: 29.917| Val Acc: 29.467\n",
            "Epoch 025: | Train Loss: 2.08549 | Val Loss: 10137.31502 | Train Acc: 29.616| Val Acc: 28.933\n",
            "Epoch 026: | Train Loss: 2.08464 | Val Loss: 11666.23161 | Train Acc: 29.559| Val Acc: 29.983\n",
            "Epoch 027: | Train Loss: 2.08643 | Val Loss: 10513.79309 | Train Acc: 28.721| Val Acc: 27.750\n",
            "Epoch 028: | Train Loss: 2.08298 | Val Loss: 2793.14788 | Train Acc: 28.954| Val Acc: 26.283\n",
            "Epoch 029: | Train Loss: 2.08172 | Val Loss: 6675.83005 | Train Acc: 28.831| Val Acc: 29.700\n",
            "Epoch 030: | Train Loss: 2.08363 | Val Loss: 17059.15966 | Train Acc: 29.131| Val Acc: 28.917\n",
            "Epoch 031: | Train Loss: 2.08001 | Val Loss: 2473.20187 | Train Acc: 29.055| Val Acc: 30.400\n",
            "Epoch 032: | Train Loss: 2.08249 | Val Loss: 13624.19058 | Train Acc: 28.744| Val Acc: 29.367\n",
            "Epoch 033: | Train Loss: 2.08264 | Val Loss: 17915.52075 | Train Acc: 28.971| Val Acc: 28.150\n",
            "Epoch 034: | Train Loss: 2.08149 | Val Loss: 10928.46885 | Train Acc: 28.721| Val Acc: 29.600\n",
            "Epoch 035: | Train Loss: 2.08142 | Val Loss: 1734.35373 | Train Acc: 29.633| Val Acc: 30.567\n",
            "Epoch 036: | Train Loss: 2.07794 | Val Loss: 9515.40121 | Train Acc: 29.040| Val Acc: 27.917\n",
            "Epoch 037: | Train Loss: 2.08229 | Val Loss: 25983.14968 | Train Acc: 29.720| Val Acc: 30.133\n",
            "Epoch 038: | Train Loss: 2.08071 | Val Loss: 1432.83926 | Train Acc: 29.130| Val Acc: 29.917\n",
            "Epoch 039: | Train Loss: 2.08376 | Val Loss: 367.56971 | Train Acc: 28.745| Val Acc: 30.517\n",
            "Epoch 040: | Train Loss: 2.07943 | Val Loss: 1335.69362 | Train Acc: 29.121| Val Acc: 28.300\n",
            "Epoch 041: | Train Loss: 2.07948 | Val Loss: 9771.56083 | Train Acc: 28.739| Val Acc: 30.400\n",
            "Epoch 042: | Train Loss: 2.07936 | Val Loss: 2381.89057 | Train Acc: 28.443| Val Acc: 27.500\n",
            "Epoch 043: | Train Loss: 2.08028 | Val Loss: 2208.52198 | Train Acc: 28.329| Val Acc: 27.567\n",
            "Epoch 044: | Train Loss: 2.07981 | Val Loss: 22611.25744 | Train Acc: 28.208| Val Acc: 30.033\n",
            "Epoch 045: | Train Loss: 2.08023 | Val Loss: 70442.64343 | Train Acc: 28.729| Val Acc: 28.817\n",
            "Epoch 046: | Train Loss: 2.07702 | Val Loss: 96489.89292 | Train Acc: 28.957| Val Acc: 27.950\n",
            "Epoch 047: | Train Loss: 2.07708 | Val Loss: 189996.89345 | Train Acc: 28.622| Val Acc: 28.233\n",
            "Epoch 048: | Train Loss: 2.07834 | Val Loss: 94457.25258 | Train Acc: 28.389| Val Acc: 24.617\n",
            "Epoch 049: | Train Loss: 2.07561 | Val Loss: 73518.89232 | Train Acc: 27.840| Val Acc: 27.717\n",
            "Epoch 050: | Train Loss: 2.07939 | Val Loss: 71452.84364 | Train Acc: 27.964| Val Acc: 27.233\n",
            "Epoch 051: | Train Loss: 2.07497 | Val Loss: 98053.63825 | Train Acc: 28.124| Val Acc: 28.850\n",
            "Epoch 052: | Train Loss: 2.07550 | Val Loss: 21134.45872 | Train Acc: 28.349| Val Acc: 26.150\n",
            "Epoch 053: | Train Loss: 2.07340 | Val Loss: 102997.78340 | Train Acc: 28.740| Val Acc: 30.683\n",
            "Epoch 054: | Train Loss: 2.07562 | Val Loss: 261603.24997 | Train Acc: 28.594| Val Acc: 28.933\n",
            "Epoch 055: | Train Loss: 2.07691 | Val Loss: 99957.51204 | Train Acc: 28.372| Val Acc: 23.867\n",
            "Epoch 056: | Train Loss: 2.07384 | Val Loss: 118652.82360 | Train Acc: 27.952| Val Acc: 27.267\n",
            "Epoch 057: | Train Loss: 2.07100 | Val Loss: 172643.98436 | Train Acc: 27.348| Val Acc: 28.283\n",
            "Epoch 058: | Train Loss: 2.07204 | Val Loss: 666193.15044 | Train Acc: 27.289| Val Acc: 26.267\n",
            "Epoch 059: | Train Loss: 2.07505 | Val Loss: 372572.62085 | Train Acc: 27.486| Val Acc: 26.667\n",
            "Epoch 060: | Train Loss: 2.07412 | Val Loss: 158037.47349 | Train Acc: 27.714| Val Acc: 27.233\n",
            "Epoch 061: | Train Loss: 2.07305 | Val Loss: 150107.91074 | Train Acc: 27.056| Val Acc: 29.000\n",
            "Epoch 062: | Train Loss: 2.07294 | Val Loss: 456422.17597 | Train Acc: 28.088| Val Acc: 25.900\n",
            "Epoch 063: | Train Loss: 2.07281 | Val Loss: 341090.92675 | Train Acc: 28.122| Val Acc: 29.367\n",
            "Epoch 064: | Train Loss: 2.07680 | Val Loss: 216518.36054 | Train Acc: 28.470| Val Acc: 25.800\n",
            "Epoch 065: | Train Loss: 2.07384 | Val Loss: 475369.66166 | Train Acc: 28.735| Val Acc: 25.650\n",
            "Epoch 066: | Train Loss: 2.07136 | Val Loss: 394372.83327 | Train Acc: 28.105| Val Acc: 28.067\n",
            "Epoch 067: | Train Loss: 2.07162 | Val Loss: 228743.61612 | Train Acc: 28.620| Val Acc: 28.200\n",
            "Epoch 068: | Train Loss: 2.07254 | Val Loss: 802155.83138 | Train Acc: 28.722| Val Acc: 26.817\n",
            "Epoch 069: | Train Loss: 2.07282 | Val Loss: 661983.71457 | Train Acc: 27.795| Val Acc: 26.617\n",
            "Epoch 070: | Train Loss: 2.07184 | Val Loss: 718685.80108 | Train Acc: 28.758| Val Acc: 29.550\n",
            "Epoch 071: | Train Loss: 2.07194 | Val Loss: 845922.52596 | Train Acc: 28.198| Val Acc: 28.067\n",
            "Epoch 072: | Train Loss: 2.06676 | Val Loss: 33456.75133 | Train Acc: 28.855| Val Acc: 26.433\n",
            "Epoch 073: | Train Loss: 2.07567 | Val Loss: 722177.57625 | Train Acc: 28.822| Val Acc: 26.400\n",
            "Epoch 074: | Train Loss: 2.07292 | Val Loss: 707662.10774 | Train Acc: 28.598| Val Acc: 28.167\n",
            "Epoch 075: | Train Loss: 2.07313 | Val Loss: 930361.33301 | Train Acc: 28.945| Val Acc: 29.100\n",
            "Epoch 076: | Train Loss: 2.07248 | Val Loss: 533488.26693 | Train Acc: 29.104| Val Acc: 29.267\n",
            "Epoch 077: | Train Loss: 2.07265 | Val Loss: 908210.72409 | Train Acc: 29.026| Val Acc: 27.933\n",
            "Epoch 078: | Train Loss: 2.06992 | Val Loss: 871982.64159 | Train Acc: 28.704| Val Acc: 28.383\n",
            "Epoch 079: | Train Loss: 2.07151 | Val Loss: 91102.55012 | Train Acc: 28.997| Val Acc: 25.467\n",
            "Epoch 080: | Train Loss: 2.07227 | Val Loss: 261304.38751 | Train Acc: 27.392| Val Acc: 26.883\n",
            "Epoch 081: | Train Loss: 2.06321 | Val Loss: 160339.70195 | Train Acc: 28.540| Val Acc: 28.833\n",
            "Epoch 082: | Train Loss: 2.06799 | Val Loss: 522967.66813 | Train Acc: 28.002| Val Acc: 25.967\n",
            "Epoch 083: | Train Loss: 2.06762 | Val Loss: 941645.51634 | Train Acc: 28.817| Val Acc: 31.167\n",
            "Epoch 084: | Train Loss: 2.06711 | Val Loss: 704007.12494 | Train Acc: 28.339| Val Acc: 29.300\n",
            "Epoch 085: | Train Loss: 2.06689 | Val Loss: 74465.28450 | Train Acc: 27.960| Val Acc: 24.617\n",
            "Epoch 086: | Train Loss: 2.06630 | Val Loss: 744452.31745 | Train Acc: 27.780| Val Acc: 26.700\n",
            "Epoch 087: | Train Loss: 2.06615 | Val Loss: 1128318.28384 | Train Acc: 28.511| Val Acc: 27.833\n",
            "Epoch 088: | Train Loss: 2.07060 | Val Loss: 307838.80481 | Train Acc: 28.330| Val Acc: 27.733\n",
            "Epoch 089: | Train Loss: 2.07296 | Val Loss: 710410.60894 | Train Acc: 27.410| Val Acc: 28.267\n",
            "Epoch 090: | Train Loss: 2.07139 | Val Loss: 590309.76246 | Train Acc: 27.555| Val Acc: 28.617\n",
            "Epoch 091: | Train Loss: 2.06853 | Val Loss: 1580330.05141 | Train Acc: 27.760| Val Acc: 29.000\n",
            "Epoch 092: | Train Loss: 2.07133 | Val Loss: 627231.89043 | Train Acc: 28.432| Val Acc: 29.233\n",
            "Epoch 093: | Train Loss: 2.06951 | Val Loss: 638149.67950 | Train Acc: 28.478| Val Acc: 25.450\n",
            "Epoch 094: | Train Loss: 2.06591 | Val Loss: 453193.78848 | Train Acc: 28.092| Val Acc: 26.733\n",
            "Epoch 095: | Train Loss: 2.06706 | Val Loss: 663929.59554 | Train Acc: 27.685| Val Acc: 28.033\n",
            "Epoch 096: | Train Loss: 2.06874 | Val Loss: 1461571.06071 | Train Acc: 28.489| Val Acc: 27.783\n",
            "Epoch 097: | Train Loss: 2.07202 | Val Loss: 491952.25430 | Train Acc: 27.938| Val Acc: 24.667\n",
            "Epoch 098: | Train Loss: 2.06959 | Val Loss: 353589.28803 | Train Acc: 27.571| Val Acc: 27.683\n",
            "Epoch 099: | Train Loss: 2.06765 | Val Loss: 1121688.03408 | Train Acc: 27.647| Val Acc: 24.117\n",
            "Epoch 100: | Train Loss: 2.06725 | Val Loss: 536980.43247 | Train Acc: 27.727| Val Acc: 25.133\n",
            "Epoch 101: | Train Loss: 2.06734 | Val Loss: 1287397.73438 | Train Acc: 27.453| Val Acc: 27.483\n",
            "Epoch 102: | Train Loss: 2.06644 | Val Loss: 742246.90434 | Train Acc: 27.367| Val Acc: 25.217\n",
            "Epoch 103: | Train Loss: 2.06764 | Val Loss: 646852.30231 | Train Acc: 27.799| Val Acc: 25.717\n",
            "Epoch 104: | Train Loss: 2.06853 | Val Loss: 680064.31776 | Train Acc: 27.544| Val Acc: 27.300\n",
            "Epoch 105: | Train Loss: 2.06949 | Val Loss: 269335.61448 | Train Acc: 27.719| Val Acc: 26.833\n",
            "Epoch 106: | Train Loss: 2.06933 | Val Loss: 1019548.76585 | Train Acc: 28.525| Val Acc: 28.900\n",
            "Epoch 107: | Train Loss: 2.06707 | Val Loss: 301171.57636 | Train Acc: 28.678| Val Acc: 28.967\n",
            "Epoch 108: | Train Loss: 2.07070 | Val Loss: 727093.70456 | Train Acc: 27.828| Val Acc: 24.000\n",
            "Epoch 109: | Train Loss: 2.06886 | Val Loss: 1136512.73966 | Train Acc: 28.067| Val Acc: 26.317\n",
            "Epoch 110: | Train Loss: 2.07073 | Val Loss: 850655.89362 | Train Acc: 27.650| Val Acc: 28.333\n",
            "Epoch 111: | Train Loss: 2.06433 | Val Loss: 1263565.57211 | Train Acc: 27.907| Val Acc: 26.233\n",
            "Epoch 112: | Train Loss: 2.06565 | Val Loss: 292323.12707 | Train Acc: 27.730| Val Acc: 26.983\n",
            "Epoch 113: | Train Loss: 2.06991 | Val Loss: 224747.24413 | Train Acc: 29.076| Val Acc: 27.817\n",
            "Epoch 114: | Train Loss: 2.06678 | Val Loss: 391105.37867 | Train Acc: 28.268| Val Acc: 27.517\n",
            "Epoch 115: | Train Loss: 2.06370 | Val Loss: 828855.97259 | Train Acc: 28.233| Val Acc: 22.317\n",
            "Epoch 116: | Train Loss: 2.06548 | Val Loss: 330836.47893 | Train Acc: 27.689| Val Acc: 26.333\n",
            "Epoch 117: | Train Loss: 2.06692 | Val Loss: 115184.96050 | Train Acc: 28.544| Val Acc: 29.267\n",
            "Epoch 118: | Train Loss: 2.06984 | Val Loss: 104655.90074 | Train Acc: 28.920| Val Acc: 28.617\n",
            "Epoch 119: | Train Loss: 2.07053 | Val Loss: 314492.42124 | Train Acc: 28.792| Val Acc: 30.017\n",
            "Epoch 120: | Train Loss: 2.06504 | Val Loss: 939151.21625 | Train Acc: 28.819| Val Acc: 25.650\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ug_OAiDZIYS",
        "outputId": "3fda3b67-132d-48ec-d07a-8564973886df"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ],\n",
              "       [0.01639344, 0.03921569, 0.        , ..., 0.04918033, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.01960784, 0.109375  , ..., 0.03278689, 0.        ,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.03846154],\n",
              "       [0.        , 0.        , 0.        , ..., 0.01639344, 0.        ,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
              "        0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIzlwMAK3WF2"
      },
      "source": [
        "test_dataset = TensorDataset(torch.from_numpy(np.array(X_test)).float())\n",
        "test_loader = DataLoader(test_dataset, batch_size = 100000, shuffle = False)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1p3v_qVUxHUE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9e7c9c-6ba9-49fb-c7ae-bdea8aa0bd8c"
      },
      "source": [
        "model.eval()\n",
        "#pred_array\n",
        "for _,data in enumerate(test_loader,0):\n",
        "    features = data[0]\n",
        "    print(features.size())\n",
        "    features = features.to(device, dtype=torch.float)\n",
        "    \n",
        "    with torch.set_grad_enabled(False):\n",
        "        y_pred = model(features)\n",
        "        y_pred_softmax = torch.log_softmax(y_pred,dim=1)\n",
        "        pred_array = torch.exp(y_pred_softmax).detach().cpu().numpy()\n",
        "        "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([100000, 75])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdNSLlnGbE2G",
        "outputId": "94b5c0d3-3510-41ca-b56a-b545cd4ee264"
      },
      "source": [
        "pred_array"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.11814564, 0.3126012 , 0.21161571, ..., 0.03348818, 0.02726108,\n",
              "        0.10478695],\n",
              "       [0.11708076, 0.1104469 , 0.12919523, ..., 0.11900762, 0.12005934,\n",
              "        0.13783924],\n",
              "       [0.10279761, 0.07562888, 0.08987974, ..., 0.09986607, 0.11476129,\n",
              "        0.11494163],\n",
              "       ...,\n",
              "       [0.11307155, 0.1944761 , 0.18790053, ..., 0.07482366, 0.06688733,\n",
              "        0.13342132],\n",
              "       [0.11564596, 0.05192663, 0.07083263, ..., 0.16156135, 0.17846762,\n",
              "        0.12139437],\n",
              "       [0.10802732, 0.07727382, 0.09466958, ..., 0.1327214 , 0.14149417,\n",
              "        0.12622699]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "i_oxIwnaU7gV",
        "outputId": "550100e9-8d40-49d6-8b53-1031bdd9b79c"
      },
      "source": [
        "sub = pd.read_csv(\"./sample_submission.csv\")\n",
        "sub.loc[:,\"Class_1\":\"Class_9\"] = pred_array\n",
        "sub = sub.set_index(\"id\")\n",
        "sub.head()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Class_1</th>\n",
              "      <th>Class_2</th>\n",
              "      <th>Class_3</th>\n",
              "      <th>Class_4</th>\n",
              "      <th>Class_5</th>\n",
              "      <th>Class_6</th>\n",
              "      <th>Class_7</th>\n",
              "      <th>Class_8</th>\n",
              "      <th>Class_9</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>200000</th>\n",
              "      <td>0.118146</td>\n",
              "      <td>0.312601</td>\n",
              "      <td>0.211616</td>\n",
              "      <td>0.121470</td>\n",
              "      <td>0.022583</td>\n",
              "      <td>0.048049</td>\n",
              "      <td>0.033488</td>\n",
              "      <td>0.027261</td>\n",
              "      <td>0.104787</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200001</th>\n",
              "      <td>0.117081</td>\n",
              "      <td>0.110447</td>\n",
              "      <td>0.129195</td>\n",
              "      <td>0.092869</td>\n",
              "      <td>0.062473</td>\n",
              "      <td>0.111029</td>\n",
              "      <td>0.119008</td>\n",
              "      <td>0.120059</td>\n",
              "      <td>0.137839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200002</th>\n",
              "      <td>0.102798</td>\n",
              "      <td>0.075629</td>\n",
              "      <td>0.089880</td>\n",
              "      <td>0.087170</td>\n",
              "      <td>0.068090</td>\n",
              "      <td>0.246864</td>\n",
              "      <td>0.099866</td>\n",
              "      <td>0.114761</td>\n",
              "      <td>0.114942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200003</th>\n",
              "      <td>0.122061</td>\n",
              "      <td>0.090853</td>\n",
              "      <td>0.111537</td>\n",
              "      <td>0.088252</td>\n",
              "      <td>0.058927</td>\n",
              "      <td>0.106888</td>\n",
              "      <td>0.141726</td>\n",
              "      <td>0.142828</td>\n",
              "      <td>0.136927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200004</th>\n",
              "      <td>0.111355</td>\n",
              "      <td>0.100992</td>\n",
              "      <td>0.120116</td>\n",
              "      <td>0.058950</td>\n",
              "      <td>0.086285</td>\n",
              "      <td>0.153778</td>\n",
              "      <td>0.116448</td>\n",
              "      <td>0.121689</td>\n",
              "      <td>0.130386</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Class_1   Class_2   Class_3  ...   Class_7   Class_8   Class_9\n",
              "id                                    ...                              \n",
              "200000  0.118146  0.312601  0.211616  ...  0.033488  0.027261  0.104787\n",
              "200001  0.117081  0.110447  0.129195  ...  0.119008  0.120059  0.137839\n",
              "200002  0.102798  0.075629  0.089880  ...  0.099866  0.114761  0.114942\n",
              "200003  0.122061  0.090853  0.111537  ...  0.141726  0.142828  0.136927\n",
              "200004  0.111355  0.100992  0.120116  ...  0.116448  0.121689  0.130386\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Id4eS1MXYW-6"
      },
      "source": [
        "sub.to_csv(\"./submission_NN.csv\")"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dygpFRhjYgpB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}